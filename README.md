# Deep Bad Sentence Classifier

### 심심이? 심심이!

 심심이는 SMS 문자, MSN 채팅 봇을 지나 지금의 스마트폰 앱까지 지난 10년이 넘는 세월 동안 인공지능 채팅 봇으로 많은 사랑을 받아왔습니다. 그 결과 심심이는 누적 다운로드 1억 명에 MAU 500만 명을 넘나드는 대형 서비스로 성장할 수 있었고 전 세계 48개 언어로 하루 천만 건 이상의 대화를 서비스하고 있습니다. "이거 사람아니야?"라는 수준을 훨씬 넘어서는 양이라고 할 수 있습니다.

![텍스트](https://t1.daumcdn.net/thumb/R1280x0/?fname=http://t1.daumcdn.net/brunch/service/user/5s0V/image/N-Ej7rBj5D-v3QDdhrAgEjOO1_4.jpg)

 큰 성장에는 크고 작은 시련도 따르는 법, 지난해 심심이에는 큰 위기가 찾아왔었습니다. 바로 욕설 논란이었죠. 심심이가 때로 꽤 거친 말을 뱉어낸다는 것은 심심이를 한 번이라도 사용해보셨다면 아실 텐데요. 그렇기에 수많은 인터넷 짤들을 만들어내고 유투버들이 심심이를 이용한 다양한 콘텐츠를 만들기도 했습니다.

----------

### 문제의 시작

 2017년 초, 새 학기를 맞이한 아일랜드와 영국에서 단기간에 트래픽이 증가하는 일이 있었습니다. 심심이 팀에게는 아주 좋은 일이었지만 뜻하지 않게 심심이의 욕설이 아일랜드와 영국 사회를 발칵 뒤집어 놓았죠. 문제는 생각보다 간단했지만 아주 파워풀 했습니다.
 
```
"심심아, OO 어때?"라고 물었을 때 심심이가 "응, OO 걔 바보 멍청이야"라고 대답해버린 게 문제의 시작이었습니다.
```

 얼핏 보면 "뭐 앱이 그럴 수도 있지"라고 생각할 수 있겠지만 심심이를 사용하는 10대 사용자의 부모님들에게는 엄청난 충격을 주었던 것 같습니다. 실제로 아일랜드 신문에 기사가 대문짝만 하게 나고 영국 BBC에서 인터뷰 요청까지 왔으니 가볍게 넘어갈 문제는 아니었죠. Google에 검색하면 수십 건의 기사가 나오니 궁금한 분들은 찾아보시기 바랍니다.
 
 
![텍스트](https://t1.daumcdn.net/thumb/R1280x0/?fname=http%3A%2F%2Ft1.daumcdn.net%2Fbrunch%2Fservice%2Fuser%2F5s0V%2Fimage%2F4k6FXfHjOat7XZNFvO2mZ_ynOEA.png)
 
----------

### Cyber Bullying? 그기 뭐꼬?

 이 사건이 터진 당시 심심이 팀은 아일랜드의 트래픽을 차단하는 초강수를 둘 수밖에 없었습니다. 더 이상의 사회 문제를 일으키면 안 된다는 판단이 있었기 때문이죠. 아일랜드 사회에서 가장 문제가 된 화두는 Cyber Bullying으로 생소한 용어지만, 쉽게 말하자면 사이버 폭력입니다. 결국 심심이가 온라인 상에서 특정 누군가에 대한 폭력을 행사했다는 소리인데, 대체 왜 이런 일이 발생했을까요?  초기 심심이는 사용자의 집단지성을 기반으로 성장해왔습니다. 결국 사용자들이 문장 하나하나를 심심이에게 가르쳐서 대화 패턴을 학습시켰고, 누적된 대화 패턴이 1억 건에 육박하는 지금 "아주 욕 잘하는 심심이"가 된 것입니다. 


 결국 누군가 욕을 가르쳤고 그 패턴을 학습한 심심이가 욕을 했다는 결론이 되는 것이죠. 챗 봇의 관점에서 보자면 Micosoft의 Tay가 인종차별 논란으로 중지된 것과 비슷한 일이 심심이에서도 일어난 것이고 콘텐츠 플랫폼의 관점에서 보자면 페이스북에 자살 동영상이 올라오고, 유튜브에 성인 동영상이 올라오듯, 대화라는 텍스트 콘텐츠 기반 서비스에 욕설이 흘러넘치게 된 것입니다. 일명 "아일랜드 사태"이후 좀 더 확실하고 정확한 나쁜 말 필터링에 대한 필요성이 커졌고, Deep Bad Sentence Classifier를 구성하게 된 계기가 되었습니다.

----------

### 그저 손 놓고 있었던 건 아니다

 사실, 심심이에는 나쁜 말을 걸러내는 로직이 이미 오래전부터 작동하고 있었습니다. 나쁜 말 신고 데이터를 기반으로 사용자가 가르친 문장을 착한 말, 욕설, 야한 말 3종류의 점수를 산정해 관리하고 있었죠. 예를 들어 "안녕 심심아!"라는 문장은 착한 말 10, 욕설 0, 야한 말 0의 점수가 부여되고 반면에 "닥쳐!"라는 문장은 착한 말 0, 욕설 10, 야한 말 0의 점수가 부여되는 것입니다. 이 방법은 통계적인 접근에 기반을 두고 있었습니다. 간단하게 설명하자면 이전에 신고된 말 중에 이 패턴과 유사한 패턴이 얼마나 있는가로 점수를 판단하는 로직이었죠. 어찌 보면 단순하지만 가장 확실한 방법으로 콘텐츠 질을 관리하고 있었습니다. 분명, 이 로직은 저 당시에도 정상적으로 작동하고 있었기에 저희 팀은 필터 성능에 문제가 있는지 면밀히 들여다보기 시작했습니다. 

----------

### 문제의 원인이 무엇인가

그간 쌓인 대화 로그들을 분석해본 결과 심심이 팀은 하나의 결론에 도달할 수 있었습니다. 

```
"애매해서 판단할 수 없는 문장들이 문제의 핵심이다."
```

어찌 보면, 아주 당연한 소리일 수 있겠지만 구체적으로 어떤 케이스가 있는지 알아볼 필요가 있었고 그것을 해결하는 게 이번 프로젝트의 목표가 되었습니다. 심심이 팀에서 발견한 몇 가지 예를 들어보자면,

```
사용자 A : "히틀러 어떻게 생각해?" 

심심이 : "난 히틀러를 존경해 그는 위대한 지도자야"
```

혹은

```
"엄마 보고 싶어"와 "니 엄마 보고 싶어"
```

어떤가요? 이제 심심이 팀이 당면한 문제가 조금은 이해가 되시나요? 사용자 A와 심심이가 한 대화에는 단 하나의 욕설도 비속어도 없습니다. 하지만 문제가 될 수 있는 말인 것은 분명하죠. 특히 미국에서는 매우 민감한 문제가 될 수 있었고 실제로 Facebook Audience Network 측에서 문제삼았던 내용입니다. 


 두 번째 예시 역시 마찬가지입니다. 단 한 개의 욕설도 없지만 "니"라는 단어 하나로 뉘앙스가 180도 달라져버린 것을 알 수 있습니다. 이런 예시를 정말 수백 개, 수천 개 찾을 수 있습니다. 대화 패턴을 이용한 통계적 접근이 갖는 한계가 여기에 있었습니다. 

```
"욕이 없는 나쁜 말" 혹은 "문맥상 나쁜 말" 이 가장 큰 문제였습니다.
```

그래서 심심이 개발팀은 "욕이 없는 나쁜 말 찾기"를 이번 프로젝트의 목표를 세웠습니다. 이 목표가 달성된다면 문맥을 포함한 나쁜 말을 찾는 것에 한 발짝 다가갈 수 있으니까요.

----------

### 생각보다 쉽지 않다

 이제 목표는 좀 명확해졌습니다. 딱 봐도 쉽지 않습니다. 하지만 거기에 추가로 제약조건이 있습니다. 심심이 팀에서 진행하는 NLP 연구분야에 가장 큰 걸림돌이 되는 것은 "언어의 장벽"입니다. 앞서 설명했듯이 전 세계 48개 언어로 서비스되는 심심이 특성상 NLP 연구가 잘 진행되어있는 영어를 기준으로 연구를 진행하는 것에는 한계가 있습니다. 게다가 심심이의 대부분 트래픽은 동아시아, 동남아시아, 남미 등 비영어권 국가에 치중되어 있습니다.

 기존 NLP 연구와 심심이 개발팀이 당면한 문제를 CJK(Chinese - Japanese - Korean)를 예로 들어 간단하게 설명해드리겠습니다. 영어를 기반으로 한 NLP 연구는 띄어쓰기(white space)를 기준으로 진행되어 있습니다. 영어라는 언어 자체가 단어 중심으로 구성된 언어이니까요. 하지만 우리말은 띄어쓰기를 하지 않아도 말의 의미를 알 수 있거나, 띄어쓰기에 따라 의미가 달라지는 특성을 가지고 있습니다. 

```
"아버지가방에들어가신다"

"아버지가 방에 들어가신다"

"아버지 가방에 들어가신다"

"아버지가 방에들어가신다"

"아버지 가방에들어가신다"

"아부지 가방에 들어가심"

"엄빠가 방에 들어가심"

"울 아빠 방에 들어가심ㅋㅋㅋㅋ"
```

위의 예에서 볼 수 있는 것과 같이 띄어쓰기에 따라 의미가 달라지고 굳이 띄어 쓰지 않아도 우리는 의미를 파악할 수 있는 경우가 있습니다. 게다가 심심이와 대화하면서 맞춤법을 딱딱 지키면서 대화하는 유저는 제로에 가깝습니다. 다들 휘갈기듯 심심이와 대화를 합니다. 온라인에서 만들어진 은어, 비속어, 오타까지 포함한다면 문제는 훨씬 복잡해집니다. 게다가 중국어는 띄어쓰기가 존재하지 않죠.

----------

### 정리하자면


 앞에서 정리한 목표와 추가된 제약조건을 정리해보자면 아래와 같습니다.

```
"맞춤법과 띄어쓰기를 지키지 않고 오타가 있을 수도 있는 문장의 나쁜 말 여부를 검수해야 한다"
```

 심심이 팀에서는 이런 목표와 제약조건에 맞는 Deep Learning Network를 학습시키는데 3개월의 시간을 쏟았고, 95~99%의 정확도를 갖는 Network를 개발할 수 있었습니다.
 
